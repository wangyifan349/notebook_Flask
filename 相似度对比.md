# 🚀 向量相似度计算详解（基于人脸特征与文本语义向量）

## 📚 目录

- [背景介绍](#背景介绍)
- [向量距离与相似度指标](#向量距离与相似度指标)
  - [Lp 距离](#lp-距离)
  - [余弦相似度](#余弦相似度)
- [🛠 应用场景](#应用场景)
  - [👤 人脸特征向量对比](#人脸特征向量对比)
  - [💬 文本语义向量对比 —— 以 Sentence-BERT 为例](#文本语义向量对比--以-sentence-bert-为例)
- [📖 示例代码（Python）](#示例代码python)
- [🔍 总结](#总结)
- [📑 参考资料](#参考资料)

---

## 🔎 背景介绍

现代机器学习任务中，数据多以向量形式表示。向量相似度计算是判断样本间相似程度的基础，广泛应用于图像检索、文本理解和人脸识别等领域。  
本文介绍常用的向量距离和相似度计算方法，并结合人脸特征和文本语义向量的典型应用。

---

## ➡️ 向量距离与相似度指标

### 🔢 Lp 距离

给定两个向量 X = (x1, x2, ..., xn)、Y = (y1, y2, ..., yn)，Lp 距离定义为：

> Lp距离 = (|x₁ - y₁|ᵖ + |x₂ - y₂|ᵖ + ... + |xₙ - yₙ|ᵖ)^(1/p)

- p=1：**L1距离（曼哈顿距离）**，计算对应元素绝对差值之和
- p=2：**L2距离（欧氏距离）**，计算元素差值平方和的平方根

⚠️ 特点：  
- L1距离对异常值更鲁棒  
- L2距离反映实际空间间距，使用广泛  

### 📐 余弦相似度

余弦相似度用于衡量向量夹角，计算公式：

> 余弦相似度 = (X · Y) / (||X|| * ||Y||)

- “·” 为点积  
- “||X||” 为向量模长  

取值范围：[-1, 1]，越接近1表示向量方向越相近。  
适合归一化向量比较，常用在文本和人脸特征向量中。

---

## 🛠 应用场景

### 👤 人脸特征向量对比

流程：

1. 🖼️ 人脸检测定位区域  
2. 🔍 使用深度神经网络提取人脸特征向量，通常归一化为单位向量  
3. 📊 使用L2距离或余弦相似度计算特征向量相似度，用于判断是否为同一人  

通常：

- 余弦相似度越大，表示越可能是同一人  
- L2距离越小，表示特征越接近  

```python
import numpy as np
import face_recognition
from PIL import Image, ImageDraw

def l2_distance(a: np.ndarray, b: np.ndarray) -> float:
    """计算 L2（欧式）距离"""
    return np.linalg.norm(a - b)

def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """计算余弦相似度"""
    dot = np.dot(a, b)
    return dot / (np.linalg.norm(a) * np.linalg.norm(b))

def load_and_encode(image_path: str) -> np.ndarray:
    """
    1. 读取图像
    2. 检测人脸并提取第一个人脸的 128-d 特征
    """
    image = face_recognition.load_image_file(image_path)
    encodings = face_recognition.face_encodings(image)
    if not encodings:
        raise ValueError(f"未在 {image_path} 中检测到人脸！")
    return encodings[0]

# ———— 以下为脚本执行部分 ————

# 指定两张待比较的人脸图片
img1_path = "face1.jpg"
img2_path = "face2.jpg"

# 提取特征向量
feat1 = load_and_encode(img1_path)
feat2 = load_and_encode(img2_path)

# 计算相似度
l2_dist = l2_distance(feat1, feat2)
cos_sim = cosine_similarity(feat1, feat2)

# 打印结果
print(f"Feature vector 1 (前5维): {feat1[:5]}")
print(f"Feature vector 2 (前5维): {feat2[:5]}")
print(f"L2 distance: {l2_dist:.4f}")
print(f"Cosine similarity: {cos_sim:.4f}")

# 使用 face_recognition 的默认阈值 0.6 来判断是否同一个人
threshold = 0.6
is_same = l2_dist < threshold
print(f"使用 L2 < {threshold} 判定同人: {is_same}")

# 可视化：在 img1 上画出检测到的人脸框
image = Image.open(img1_path)
face_locations = face_recognition.face_locations(np.array(image))
draw = ImageDraw.Draw(image)
for top, right, bottom, left in face_locations:
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 255, 0), width=2)
# 展示带框图
image.show()
```

⚠️ 阈值由具体模型和应用场景决定。

---

### 💬 文本语义向量对比 —— 以 Sentence-BERT 为例

Sentence-BERT (SBERT) 是基于 BERT 训练的句子表示模型，将句子映射为固定维度向量。

计算流程：

1. 使用 SBERT 对句子编码，得到语义向量  
2. 计算两个向量之间的余弦相似度，衡量语义相似度  
3. 相似度分数用于文本匹配、检索和分类  

SBERT 大幅提升了语义匹配效率，适合大规模文本相似度计算。

---

## 📖 示例代码（Python）

```python
import numpy as np
from sentence_transformers import SentenceTransformer

def l2_distance(vec1, vec2):
    return np.linalg.norm(vec1 - vec2)

def l1_distance(vec1, vec2):
    return np.sum(np.abs(vec1 - vec2))

def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0:
        return 0
    return dot_product / (norm1 * norm2)

# 向量示例
vec_a = np.array([1.0, 2.0, 3.0])
vec_b = np.array([2.0, 3.0, 4.0])

print("L2距离:", l2_distance(vec_a, vec_b))
print("L1距离:", l1_distance(vec_a, vec_b))
print("余弦相似度:", cosine_similarity(vec_a, vec_b))

# Sentence-BERT 例子
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

sentence1 = "今天天气很好"
sentence2 = "今天的天气非常好"

embedding1 = model.encode(sentence1)
embedding2 = model.encode(sentence2)

sim = cosine_similarity(embedding1, embedding2)
print(f"句子语义相似度: {sim:.4f}")
```

---

## 🔍 总结

本文介绍了向量相似度的基本计算方法，重点阐述了 L1、L2 距离和余弦相似度指标，结合人脸特征向量和文本语义向量（Sentence-BERT）两个典型应用。示例代码展示了对应计算实现，便于快速实践。  
合理选取相似度度量方式对提高模型性能至关重要。

---

## 📑 参考资料

- 📄 FaceNet论文：https://arxiv.org/abs/1503.03832  
- 📄 Sentence-BERT论文：https://arxiv.org/abs/1908.10084  
- 🧰 Sentence-BERT开源地址：https://github.com/UKPLab/sentence-transformers  
- 📚 维基百科 - Minkowski距离：https://en.wikipedia.org/wiki/Minkowski_distance  
- 📚 维基百科 - 余弦相似度：https://en.wikipedia.org/wiki/Cosine_similarity

---
