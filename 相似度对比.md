# ğŸš€ å‘é‡ç›¸ä¼¼åº¦è®¡ç®—è¯¦è§£ï¼ˆåŸºäºäººè„¸ç‰¹å¾ä¸æ–‡æœ¬è¯­ä¹‰å‘é‡ï¼‰

## ğŸ“š ç›®å½•

- [èƒŒæ™¯ä»‹ç»](#èƒŒæ™¯ä»‹ç»)
- [å‘é‡è·ç¦»ä¸ç›¸ä¼¼åº¦æŒ‡æ ‡](#å‘é‡è·ç¦»ä¸ç›¸ä¼¼åº¦æŒ‡æ ‡)
  - [Lp è·ç¦»](#lp-è·ç¦»)
  - [ä½™å¼¦ç›¸ä¼¼åº¦](#ä½™å¼¦ç›¸ä¼¼åº¦)
- [ğŸ›  åº”ç”¨åœºæ™¯](#åº”ç”¨åœºæ™¯)
  - [ğŸ‘¤ äººè„¸ç‰¹å¾å‘é‡å¯¹æ¯”](#äººè„¸ç‰¹å¾å‘é‡å¯¹æ¯”)
  - [ğŸ’¬ æ–‡æœ¬è¯­ä¹‰å‘é‡å¯¹æ¯” â€”â€” ä»¥ Sentence-BERT ä¸ºä¾‹](#æ–‡æœ¬è¯­ä¹‰å‘é‡å¯¹æ¯”--ä»¥-sentence-bert-ä¸ºä¾‹)
- [ğŸ“– ç¤ºä¾‹ä»£ç ï¼ˆPythonï¼‰](#ç¤ºä¾‹ä»£ç python)
- [ğŸ” æ€»ç»“](#æ€»ç»“)
- [ğŸ“‘ å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

---

## ğŸ” èƒŒæ™¯ä»‹ç»

ç°ä»£æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œæ•°æ®å¤šä»¥å‘é‡å½¢å¼è¡¨ç¤ºã€‚å‘é‡ç›¸ä¼¼åº¦è®¡ç®—æ˜¯åˆ¤æ–­æ ·æœ¬é—´ç›¸ä¼¼ç¨‹åº¦çš„åŸºç¡€ï¼Œå¹¿æ³›åº”ç”¨äºå›¾åƒæ£€ç´¢ã€æ–‡æœ¬ç†è§£å’Œäººè„¸è¯†åˆ«ç­‰é¢†åŸŸã€‚  
æœ¬æ–‡ä»‹ç»å¸¸ç”¨çš„å‘é‡è·ç¦»å’Œç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œå¹¶ç»“åˆäººè„¸ç‰¹å¾å’Œæ–‡æœ¬è¯­ä¹‰å‘é‡çš„å…¸å‹åº”ç”¨ã€‚

---

## â¡ï¸ å‘é‡è·ç¦»ä¸ç›¸ä¼¼åº¦æŒ‡æ ‡

### ğŸ”¢ Lp è·ç¦»

ç»™å®šä¸¤ä¸ªå‘é‡ X = (x1, x2, ..., xn)ã€Y = (y1, y2, ..., yn)ï¼ŒLp è·ç¦»å®šä¹‰ä¸ºï¼š

> Lpè·ç¦» = (|xâ‚ - yâ‚|áµ– + |xâ‚‚ - yâ‚‚|áµ– + ... + |xâ‚™ - yâ‚™|áµ–)^(1/p)

- p=1ï¼š**L1è·ç¦»ï¼ˆæ›¼å“ˆé¡¿è·ç¦»ï¼‰**ï¼Œè®¡ç®—å¯¹åº”å…ƒç´ ç»å¯¹å·®å€¼ä¹‹å’Œ
- p=2ï¼š**L2è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ï¼‰**ï¼Œè®¡ç®—å…ƒç´ å·®å€¼å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹

âš ï¸ ç‰¹ç‚¹ï¼š  
- L1è·ç¦»å¯¹å¼‚å¸¸å€¼æ›´é²æ£’  
- L2è·ç¦»åæ˜ å®é™…ç©ºé—´é—´è·ï¼Œä½¿ç”¨å¹¿æ³›  

### ğŸ“ ä½™å¼¦ç›¸ä¼¼åº¦

ä½™å¼¦ç›¸ä¼¼åº¦ç”¨äºè¡¡é‡å‘é‡å¤¹è§’ï¼Œè®¡ç®—å…¬å¼ï¼š

> ä½™å¼¦ç›¸ä¼¼åº¦ = (X Â· Y) / (||X|| * ||Y||)

- â€œÂ·â€ ä¸ºç‚¹ç§¯  
- â€œ||X||â€ ä¸ºå‘é‡æ¨¡é•¿  

å–å€¼èŒƒå›´ï¼š[-1, 1]ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºå‘é‡æ–¹å‘è¶Šç›¸è¿‘ã€‚  
é€‚åˆå½’ä¸€åŒ–å‘é‡æ¯”è¾ƒï¼Œå¸¸ç”¨åœ¨æ–‡æœ¬å’Œäººè„¸ç‰¹å¾å‘é‡ä¸­ã€‚

---

## ğŸ›  åº”ç”¨åœºæ™¯

### ğŸ‘¤ äººè„¸ç‰¹å¾å‘é‡å¯¹æ¯”

æµç¨‹ï¼š

1. ğŸ–¼ï¸ äººè„¸æ£€æµ‹å®šä½åŒºåŸŸ  
2. ğŸ” ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæå–äººè„¸ç‰¹å¾å‘é‡ï¼Œé€šå¸¸å½’ä¸€åŒ–ä¸ºå•ä½å‘é‡  
3. ğŸ“Š ä½¿ç”¨L2è·ç¦»æˆ–ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç‰¹å¾å‘é‡ç›¸ä¼¼åº¦ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€äºº  

é€šå¸¸ï¼š

- ä½™å¼¦ç›¸ä¼¼åº¦è¶Šå¤§ï¼Œè¡¨ç¤ºè¶Šå¯èƒ½æ˜¯åŒä¸€äºº  
- L2è·ç¦»è¶Šå°ï¼Œè¡¨ç¤ºç‰¹å¾è¶Šæ¥è¿‘  

```python
import numpy as np
import face_recognition
from PIL import Image, ImageDraw

def l2_distance(a: np.ndarray, b: np.ndarray) -> float:
    """è®¡ç®— L2ï¼ˆæ¬§å¼ï¼‰è·ç¦»"""
    return np.linalg.norm(a - b)

def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    dot = np.dot(a, b)
    return dot / (np.linalg.norm(a) * np.linalg.norm(b))

def load_and_encode(image_path: str) -> np.ndarray:
    """
    1. è¯»å–å›¾åƒ
    2. æ£€æµ‹äººè„¸å¹¶æå–ç¬¬ä¸€ä¸ªäººè„¸çš„ 128-d ç‰¹å¾
    """
    image = face_recognition.load_image_file(image_path)
    encodings = face_recognition.face_encodings(image)
    if not encodings:
        raise ValueError(f"æœªåœ¨ {image_path} ä¸­æ£€æµ‹åˆ°äººè„¸ï¼")
    return encodings[0]

# â€”â€”â€”â€” ä»¥ä¸‹ä¸ºè„šæœ¬æ‰§è¡Œéƒ¨åˆ† â€”â€”â€”â€”

# æŒ‡å®šä¸¤å¼ å¾…æ¯”è¾ƒçš„äººè„¸å›¾ç‰‡
img1_path = "face1.jpg"
img2_path = "face2.jpg"

# æå–ç‰¹å¾å‘é‡
feat1 = load_and_encode(img1_path)
feat2 = load_and_encode(img2_path)

# è®¡ç®—ç›¸ä¼¼åº¦
l2_dist = l2_distance(feat1, feat2)
cos_sim = cosine_similarity(feat1, feat2)

# æ‰“å°ç»“æœ
print(f"Feature vector 1 (å‰5ç»´): {feat1[:5]}")
print(f"Feature vector 2 (å‰5ç»´): {feat2[:5]}")
print(f"L2 distance: {l2_dist:.4f}")
print(f"Cosine similarity: {cos_sim:.4f}")

# ä½¿ç”¨ face_recognition çš„é»˜è®¤é˜ˆå€¼ 0.6 æ¥åˆ¤æ–­æ˜¯å¦åŒä¸€ä¸ªäºº
threshold = 0.6
is_same = l2_dist < threshold
print(f"ä½¿ç”¨ L2 < {threshold} åˆ¤å®šåŒäºº: {is_same}")

# å¯è§†åŒ–ï¼šåœ¨ img1 ä¸Šç”»å‡ºæ£€æµ‹åˆ°çš„äººè„¸æ¡†
image = Image.open(img1_path)
face_locations = face_recognition.face_locations(np.array(image))
draw = ImageDraw.Draw(image)
for top, right, bottom, left in face_locations:
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 255, 0), width=2)
# å±•ç¤ºå¸¦æ¡†å›¾
image.show()
```

âš ï¸ é˜ˆå€¼ç”±å…·ä½“æ¨¡å‹å’Œåº”ç”¨åœºæ™¯å†³å®šã€‚

---

### ğŸ’¬ æ–‡æœ¬è¯­ä¹‰å‘é‡å¯¹æ¯” â€”â€” ä»¥ Sentence-BERT ä¸ºä¾‹

Sentence-BERT (SBERT) æ˜¯åŸºäº BERT è®­ç»ƒçš„å¥å­è¡¨ç¤ºæ¨¡å‹ï¼Œå°†å¥å­æ˜ å°„ä¸ºå›ºå®šç»´åº¦å‘é‡ã€‚

è®¡ç®—æµç¨‹ï¼š

1. ä½¿ç”¨ SBERT å¯¹å¥å­ç¼–ç ï¼Œå¾—åˆ°è¯­ä¹‰å‘é‡  
2. è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¡¡é‡è¯­ä¹‰ç›¸ä¼¼åº¦  
3. ç›¸ä¼¼åº¦åˆ†æ•°ç”¨äºæ–‡æœ¬åŒ¹é…ã€æ£€ç´¢å’Œåˆ†ç±»  

SBERT å¤§å¹…æå‡äº†è¯­ä¹‰åŒ¹é…æ•ˆç‡ï¼Œé€‚åˆå¤§è§„æ¨¡æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ã€‚

---

## ğŸ“– ç¤ºä¾‹ä»£ç ï¼ˆPythonï¼‰

```python
import numpy as np
from sentence_transformers import SentenceTransformer

def l2_distance(vec1, vec2):
    return np.linalg.norm(vec1 - vec2)

def l1_distance(vec1, vec2):
    return np.sum(np.abs(vec1 - vec2))

def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0:
        return 0
    return dot_product / (norm1 * norm2)

# å‘é‡ç¤ºä¾‹
vec_a = np.array([1.0, 2.0, 3.0])
vec_b = np.array([2.0, 3.0, 4.0])

print("L2è·ç¦»:", l2_distance(vec_a, vec_b))
print("L1è·ç¦»:", l1_distance(vec_a, vec_b))
print("ä½™å¼¦ç›¸ä¼¼åº¦:", cosine_similarity(vec_a, vec_b))

# Sentence-BERT ä¾‹å­
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

sentence1 = "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
sentence2 = "ä»Šå¤©çš„å¤©æ°”éå¸¸å¥½"

embedding1 = model.encode(sentence1)
embedding2 = model.encode(sentence2)

sim = cosine_similarity(embedding1, embedding2)
print(f"å¥å­è¯­ä¹‰ç›¸ä¼¼åº¦: {sim:.4f}")
```

---

## ğŸ” æ€»ç»“

æœ¬æ–‡ä»‹ç»äº†å‘é‡ç›¸ä¼¼åº¦çš„åŸºæœ¬è®¡ç®—æ–¹æ³•ï¼Œé‡ç‚¹é˜è¿°äº† L1ã€L2 è·ç¦»å’Œä½™å¼¦ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼Œç»“åˆäººè„¸ç‰¹å¾å‘é‡å’Œæ–‡æœ¬è¯­ä¹‰å‘é‡ï¼ˆSentence-BERTï¼‰ä¸¤ä¸ªå…¸å‹åº”ç”¨ã€‚ç¤ºä¾‹ä»£ç å±•ç¤ºäº†å¯¹åº”è®¡ç®—å®ç°ï¼Œä¾¿äºå¿«é€Ÿå®è·µã€‚  
åˆç†é€‰å–ç›¸ä¼¼åº¦åº¦é‡æ–¹å¼å¯¹æé«˜æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚

---

## ğŸ“‘ å‚è€ƒèµ„æ–™

- ğŸ“„ FaceNetè®ºæ–‡ï¼šhttps://arxiv.org/abs/1503.03832  
- ğŸ“„ Sentence-BERTè®ºæ–‡ï¼šhttps://arxiv.org/abs/1908.10084  
- ğŸ§° Sentence-BERTå¼€æºåœ°å€ï¼šhttps://github.com/UKPLab/sentence-transformers  
- ğŸ“š ç»´åŸºç™¾ç§‘ - Minkowskiè·ç¦»ï¼šhttps://en.wikipedia.org/wiki/Minkowski_distance  
- ğŸ“š ç»´åŸºç™¾ç§‘ - ä½™å¼¦ç›¸ä¼¼åº¦ï¼šhttps://en.wikipedia.org/wiki/Cosine_similarity

---
